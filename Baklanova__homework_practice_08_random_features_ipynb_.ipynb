{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Валерия Бакланова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 1.10.2021\n",
    "\n",
    "Мягкий дедлайн: 17.10.2021 23:59 МСК\n",
    "\n",
    "Жесткий дедлайн: 24.10.2021 23:59 МСК (1 неделя -- минус балл)\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Загрузите решение в свой репозиторий на github и поделитесь [ссылкой на решение в форме](https://forms.gle/ZzCaqRj6bmfpSpyL7). Не забудьте дать доступ к Вашему репозиторию, что у преподавателей была возмоожность проверить работу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mAfVGIUvAmnH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dJTBvoLKAccP"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-UGUJGXA-sk",
    "outputId": "2d5c1ef2-78d2-400d-e45d-16b7c78dd24c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        # 1-st step. PCA \n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            self.sc = StandardScaler()\n",
    "            X_std = self.sc.fit_transform(X)\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X_pca = self.pca.fit_transform(X_std)\n",
    "            self.X_pca = X_pca\n",
    "        else:\n",
    "            self.X_pca = X\n",
    "\n",
    "        # 2-nd step. sigma\n",
    "\n",
    "        var_hat_all = np.zeros(10**6)\n",
    "        for par in range(10**6):\n",
    "            i, j = np.random.randint(low=0, high=self.X_pca.shape[0], size=2)\n",
    "\n",
    "            while i-j == 0:\n",
    "              i, j = np.random.randint(low=0, high=self.X_pca.shape[0], size=2)\n",
    "  \n",
    "\n",
    "            res = np.sum((self.X_pca[i,:] - self.X_pca[j,:]) ** 2)\n",
    "            var_hat_all[par] = res\n",
    "            \n",
    "        est_med = np.median(var_hat_all)\n",
    "        self.est_med = est_med\n",
    "\n",
    "\n",
    "        # 3-d step. generating b, W\n",
    "        \n",
    "        b = np.random.uniform(-np.pi, np.pi, size=self.n_features)\n",
    "        \n",
    "        W = np.zeros((self.X_pca.shape[1], self.n_features))\n",
    "        W[:,:] = np.random.normal(loc=0, scale=np.sqrt(1/self.est_med), size=(self.X_pca.shape[1], self.n_features))\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        # 4-th step. cos \n",
    "        \n",
    "        #new_x = np.zeros((self.X_pca.shape[0], self.n_features))\n",
    "\n",
    "        # for i in range(self.n_features):\n",
    "        #     w_i = self.W[:, i].reshape(self.new_dim, 1)\n",
    "        #     new_x[:, i] = np.cos(w_i.T.dot(self.X_pca.T) + self.b[i])\n",
    "\n",
    "        # for i in range(self.X_pca.shape[0]):\n",
    "        #     cos_i = np.cos(X_pca[i,:].dot(self.W) + self.b)\n",
    "        #     new_x[i, :] = cos_i\n",
    "\n",
    "        new_x = np.cos(self.X_pca.dot(self.W) + self.b)\n",
    "\n",
    "\n",
    "        self.sc_new = StandardScaler()\n",
    "        new_x = self.sc_new.fit_transform(new_x)\n",
    "\n",
    "        self.new_x = new_x\n",
    "\n",
    "\n",
    "        # 5-th step. Fitting logreg/SVM\n",
    "\n",
    "        if self.classifier == 'logreg':\n",
    "            clf = LogisticRegression(n_jobs=-1)\n",
    "            clf.fit(self.new_x, y)\n",
    "            self.clf = clf\n",
    "        \n",
    "        if self.classifier == 'SVM':\n",
    "            clf = SVC(kernel='linear')\n",
    "            clf.fit(self.new_x, y)\n",
    "            self.clf = clf\n",
    "        \n",
    "        return self.clf\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "        \n",
    "        new_x_test = np.cos(self.X_test_pca.dot(self.W) + self.b)\n",
    "\n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred_proba = self.clf.predict_proba(new_x_test)\n",
    "        \n",
    "        return pred_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "        new_x_test = np.cos(self.X_test_pca.dot(self.W) + self.b)    \n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred = self.clf.predict(new_x_test)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yeLfur45kDW"
   },
   "source": [
    "#### RFF (logreg) - default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAxV2uad_3e0",
    "outputId": "f2b50cc9-5a06-456c-dfeb-c3787d5ea403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 119.24050879478455 seconds (fit) ---\n",
      "--- 0.6603941917419434 seconds (predict) ---\n",
      "Accuracy LogReg: 0.8671\n"
     ]
    }
   ],
   "source": [
    "RFFPipe = RFFPipeline()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "RFFPipe.fit(x_train, y_train)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "preds = RFFPipe.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy LogReg: {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.8671 > 0.84 => все ок!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sK9tGEIv0zfE"
   },
   "outputs": [],
   "source": [
    "# Сгенерируем случайную выборку из трейна для уменьшения времени расчетов\n",
    "\n",
    "x_sub, y_sub = shuffle(x_train, y_train)\n",
    "x_sub_n, y_sub_n = x_sub[:10000], y_sub[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi-7Goz_ufM5"
   },
   "source": [
    "#### RFF (logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6z6DolYtuez9",
    "outputId": "2c90b5fd-fda2-4758-9ef0-d81ff5367d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 69.50981092453003 seconds (fit) ---\n",
      "--- 0.6125786304473877 seconds (predict) ---\n",
      "Accuracy RFF(LogReg): 0.84\n"
     ]
    }
   ],
   "source": [
    "RFFPipe = RFFPipeline()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "RFFPipe.fit(x_sub_n, y_sub_n)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "preds = RFFPipe.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy RFF(LogReg): {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPP0yFpB1hg1"
   },
   "source": [
    "#### RFF (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHATQb0_1j3B",
    "outputId": "87672126-4db4-4b9e-da07-546e010a5407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 86.32675409317017 seconds (fit) ---\n",
      "--- 40.05028009414673 seconds (predict) ---\n",
      "Accuracy RFF(SVM): 0.8297\n"
     ]
    }
   ],
   "source": [
    "RFFPipe_SVM = RFFPipeline(classifier='SVM')\n",
    "\n",
    "start_time = time.time()\n",
    "RFFPipe_SVM.fit(x_sub_n, y_sub_n)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "preds = RFFPipe_SVM.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy RFF(SVM): {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRzyFSkf1MTJ"
   },
   "source": [
    "#### Линейный SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAb0EUchzLqQ",
    "outputId": "13114c62-a099-4a19-d4dc-a8c1324f3aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 34.361106395721436 seconds (fit) ---\n",
      "--- 32.75301933288574 seconds (predict) ---\n",
      "Accuracy LinearSVM: 0.7892\n"
     ]
    }
   ],
   "source": [
    "LinearSVM = SVC(kernel='linear')\n",
    "\n",
    "start_time = time.time()\n",
    "LinearSVM.fit(x_sub_n, y_sub_n)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "preds = LinearSVM.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "print('Accuracy LinearSVM: {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8znI74P1PsS"
   },
   "source": [
    "#### Ядровой SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7nVEMnjzLxZ",
    "outputId": "6b3619d7-1fea-4a1e-c23e-c0ef6c4b0d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 26.033186674118042 seconds (fit) ---\n",
      "--- 42.71866488456726 seconds (predict) ---\n",
      "Accuracy KernelSVM: 0.8195\n"
     ]
    }
   ],
   "source": [
    "KernelSVM = SVC(kernel='poly')\n",
    "\n",
    "start_time = time.time()\n",
    "KernelSVM.fit(x_sub_n, y_sub_n)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "preds = KernelSVM.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy KernelSVM: {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по качеству моделей: RFF (logreg) > RFF (SVM) > Ядровой SVM > Линейный SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по времени обучения: подход со случайными признаками обучается в 2 раза дольше, чем SVM на исходных признаках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMPpVNTm1zcr"
   },
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZAJAQwP55Cf"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIMWyeSv2Ez1"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train_std = sc.fit_transform(x_train)\n",
    "pca = PCA(n_components=50)\n",
    "x_train_pca = pca.fit_transform(x_train_std)\n",
    "\n",
    "\n",
    "x_test_std = sc.transform(x_test)\n",
    "x_test_pca = pca.transform(x_test_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXqMQxKv0s9i"
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'learning_rate': [0.05, 0.1, 0.15],\n",
    "              'n_estimators': [80, 100, 120]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqW1PGPT3ZCj",
    "outputId": "bf480c04-635b-49e5-b57b-391ccfd830b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.15],\n",
       "                         'max_depth': [4, 6, 8],\n",
       "                         'n_estimators': [80, 100, 120]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "gsearch = GridSearchCV(model, param_grid=parameters, scoring='accuracy', cv=3)\n",
    "gsearch.fit(x_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzcKJ2Gv4ZId",
    "outputId": "a13c069e-d71c-4407-f0e8-236cde491f3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8676333333333334,\n",
       " {'learning_rate': 0.15, 'max_depth': 8, 'n_estimators': 120})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_score_, gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-D5v03O0I1P",
    "outputId": "2674120f-1cb4-44d5-ec83-76386f9ed34c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 31.076138973236084 seconds (fit) ---\n",
      "--- 0.7473199367523193 seconds (predict) ---\n",
      "Accuracy lightGBM: 0.8612\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier( max_depth=8, learning_rate = 0.15, n_estimators = 120)\n",
    "start_time = time.time()\n",
    "model.fit(x_train_pca, y_train)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "preds = model.predict(x_test_pca)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "print('Accuracy lightGBM: {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В 1-ом задании у RFF (logreg) на всем трейне получилось accuracy = 0.8671 - практически аналогично результатам lightGBM! Однако RFF (logreg) работает дольше: обучение заняло 120 секунд против 31 секунды у бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий вывод: RFF показывает немного лучшее качество, однако требует значительные временные затраты на обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlYm3k-36i9L"
   },
   "source": [
    "#### 1. RFF (logreg, no PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2QIHIMbK-hW",
    "outputId": "e011811f-7bc1-49e3-dc7e-693d8da94e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 47.15490770339966 seconds (fit) ---\n",
      "--- 0.9500048160552979 seconds (predict) ---\n",
      "Accuracy LogReg (no PCA): 0.1048\n"
     ]
    }
   ],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "RFFPipe = RFFPipeline(use_PCA=False)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "RFFPipe.fit(x_train, y_train)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "preds = RFFPipe.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy LogReg (no PCA): {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получили очень низкое качество. Модель с предварительным использованием PCA работает в разы лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXLrngpr8fIZ"
   },
   "source": [
    "#### 2. n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ryzZ0X-J8eeR"
   },
   "outputs": [],
   "source": [
    "n_features = np.array(range(100, 1600, 100))\n",
    "accuracy = np.zeros(len(n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "a5f6BN3d9Bcz"
   },
   "outputs": [],
   "source": [
    "for j, i in enumerate(n_features):\n",
    "    RFFPipe = RFFPipeline(n_features=i)\n",
    "    RFFPipe.fit(x_sub_n, y_sub_n)\n",
    "    preds = RFFPipe.predict(x_test)\n",
    "    accuracy[j]= accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "9R4ybU8T9CDT",
    "outputId": "4adf74db-1a1d-495e-8857-9c4fa1dc2940"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.scatter(x = n_features, y = accuracy)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('n_features')\n",
    "plt.yticks(np.arange(0.81, 0.86,0.005))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С ростом  n_features растет качество, однако оно выходит на плато, начиная с n_features = 400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_ea-y7MBPA6"
   },
   "source": [
    "#### 3. Logreg VS SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ebHUombiBReu"
   },
   "outputs": [],
   "source": [
    "n_feat = np.array(range(1000, 1600, 100))\n",
    "acc_svm = np.zeros(len(n_feat))\n",
    "\n",
    "for j, i in enumerate(n_feat):\n",
    "  \n",
    "    RFFPipe = RFFPipeline(n_features=i, classifier='SVM')\n",
    "    RFFPipe.fit(x_sub_n, y_sub_n)\n",
    "    preds = RFFPipe.predict(x_test)\n",
    "    acc_svm[j] = accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dl2356ulCoY0",
    "outputId": "bdf0f9da-fe12-4545-89ee-922bb7456816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LogReg with different n_features: [0.8447 0.841  0.8419 0.8415 0.8435 0.8424]\n",
      "Accuracy SVM with different n_features: [0.8317, 0.83, 0.8292, 0.8303, 0.8297, 0.8284]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy LogReg with different n_features: {}'.format(accuracy[-6:]))\n",
    "print('Accuracy SVM with different n_features: {}'.format(acc_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решила сравнить модели с разным числом n_features для достоверности результата. Вывод: обе модели показывают достойное качество, однако accuracy больше в случае использования логистической регрессии + она менее времязатратная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "veQ40dt-5npU"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "IvhYq_IuMdFn"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline_ORF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        # 1-st step. PCA \n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            self.sc = StandardScaler()\n",
    "            X_std = self.sc.fit_transform(X)\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X_pca = self.pca.fit_transform(X_std)\n",
    "            self.X_pca = X_pca\n",
    "        else:\n",
    "            self.X_pca = X\n",
    "\n",
    "        # 2-nd step. sigma\n",
    "\n",
    "        var_hat_all = np.zeros(10**6)\n",
    "        for par in range(10**6):\n",
    "            i, j = np.random.randint(low=0, high=self.X_pca.shape[0], size=2)\n",
    "\n",
    "            while i-j == 0:\n",
    "              i, j = np.random.randint(low=0, high=self.X_pca.shape[0], size=2)\n",
    "  \n",
    "\n",
    "            res = np.sum((self.X_pca[i,:] - self.X_pca[j,:]) ** 2)\n",
    "            var_hat_all[par] = res\n",
    "            \n",
    "        est_med = np.median(var_hat_all)\n",
    "        self.est_med = est_med\n",
    "\n",
    "\n",
    "        # 3-d step. generating b, W\n",
    "        \n",
    "        # ******** W *********\n",
    "\n",
    "        if self.n_features == self.X_pca.shape[1]:\n",
    "\n",
    "          G = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "          G[:,:] = np.random.normal(loc=0, scale=1, size=(self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "          self.G = G\n",
    "\n",
    "          Q = scipy.linalg.qr(G)[0]\n",
    "          self.Q = Q\n",
    "\n",
    "          S = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "          diagonal = [np.random.chisquare(df=self.X_pca.shape[1]) for i in range(self.X_pca.shape[1])] \n",
    "          np.fill_diagonal(S, diagonal)\n",
    "          self.S = S\n",
    "\n",
    "          W = np.sqrt(1/self.est_med) * self.S.dot(self.Q) \n",
    "\n",
    "        if self.n_features < self.X_pca.shape[1]:\n",
    "\n",
    "          G = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "          G[:,:] = np.random.normal(loc=0, scale=1, size=(self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "          self.G = G\n",
    "\n",
    "          Q = scipy.linalg.qr(G)[0]\n",
    "          self.Q = Q\n",
    "\n",
    "          S = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "          diagonal = [np.random.chisquare(df=self.X_pca.shape[1]) for i in range(self.X_pca.shape[1])] \n",
    "          np.fill_diagonal(S, diagonal)\n",
    "          self.S = S\n",
    "\n",
    "          W = np.sqrt(1/self.est_med) * self.S.dot(self.Q) \n",
    "          W = W[:, :self.n_features]\n",
    "\n",
    "\n",
    "        if self.n_features > self.X_pca.shape[1]:\n",
    "\n",
    "          zeloe = self.n_features // self.X_pca.shape[1]\n",
    "          ostatok = self.n_features % self.X_pca.shape[1]    \n",
    "          \n",
    "          W = [0 for i in range(zeloe + min(1,ostatok))]\n",
    "\n",
    "          for i in range(zeloe):\n",
    "\n",
    "            G = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "            G[:,:] = np.random.normal(loc=0, scale=1, size=(self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "            self.G = G\n",
    "\n",
    "            Q = scipy.linalg.qr(G)[0]\n",
    "            self.Q = Q\n",
    "\n",
    "            S = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "            diagonal = [np.random.chisquare(df=self.X_pca.shape[1]) for i in range(self.X_pca.shape[1])] \n",
    "            np.fill_diagonal(S, diagonal)\n",
    "            self.S = S\n",
    "\n",
    "            W[i] = np.sqrt(1/self.est_med) * self.S.dot(self.Q)  \n",
    "      \n",
    "          if ostatok != 0:\n",
    "\n",
    "            G = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "            G[:,:] = np.random.normal(loc=0, scale=1, size=(self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "            self.G = G\n",
    "\n",
    "            Q = scipy.linalg.qr(G)[0]\n",
    "            self.Q = Q\n",
    "\n",
    "            S = np.zeros((self.X_pca.shape[1], self.X_pca.shape[1]))\n",
    "            diagonal = [np.random.chisquare(df=self.X_pca.shape[1]) for i in range(self.X_pca.shape[1])] \n",
    "            np.fill_diagonal(S, diagonal)\n",
    "            self.S = S\n",
    "\n",
    "            W_small = np.sqrt(1/self.est_med) * self.S.dot(self.Q) \n",
    "            \n",
    "            W[-1] = W_small[:, :ostatok]\n",
    "\n",
    "          \n",
    "          W_final = W[0]\n",
    "          for j in range(1,len(W)):\n",
    "\n",
    "            W_final = np.concatenate([W_final, W[j]], axis=1)\n",
    "\n",
    "          W = W_final\n",
    "\n",
    "        # ******** W *********\n",
    "\n",
    "\n",
    "        b = np.random.uniform(-np.pi, np.pi, size=self.n_features)\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        # 4-th step. cos \n",
    "\n",
    "\n",
    "        new_x = np.cos(self.X_pca.dot(self.W) + self.b)\n",
    "\n",
    "\n",
    "        self.sc_new = StandardScaler()\n",
    "        new_x = self.sc_new.fit_transform(new_x)\n",
    "\n",
    "        self.new_x = new_x\n",
    "\n",
    "\n",
    "        # 5-th step. Fitting logreg/SVM\n",
    "\n",
    "        if self.classifier == 'logreg':\n",
    "            clf = LogisticRegression(n_jobs=-1)\n",
    "            clf.fit(self.new_x, y)\n",
    "            self.clf = clf\n",
    "        \n",
    "        if self.classifier == 'SVM':\n",
    "            clf = SVC(kernel='linear')\n",
    "            clf.fit(self.new_x, y)\n",
    "            self.clf = clf\n",
    "        \n",
    "        return self.clf\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "        \n",
    "        new_x_test = np.cos(self.X_test_pca.dot(self.W) + self.b)\n",
    "\n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred_proba = self.clf.predict_proba(new_x_test)\n",
    "        \n",
    "        return pred_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "        new_x_test = np.cos(self.X_test_pca.dot(self.W) + self.b)    \n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred = self.clf.predict(new_x_test)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-5AVP5bOhi8",
    "outputId": "261b034e-d72c-4386-e848-92d111f799fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 247.59407496452332 seconds (fit) ---\n",
      "--- 1.9236578941345215 seconds (predict) ---\n",
      "Accuracy LogReg: 0.8251\n"
     ]
    }
   ],
   "source": [
    "RFFPipe = RFFPipeline_ORF(n_features=3500, new_dim=10)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "RFFPipe.fit(x_train, y_train)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "preds = RFFPipe.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy ORF(LogReg): {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализовала метод из статьи, получила хорошее, но не outstanding качество. Класс работает со всеми вариантами, в том числе для случая n_features > new_dim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Попробуем другой способ генерации признаков "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(идея взята с просторов интернета, реализация - собственная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "from scipy.stats import cauchy, laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "LlOO_7lMRsNQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline_5(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=200, use_PCA=True, classifier='logreg', gamma = 0.0001):\n",
    "  \n",
    "        self.n_features = n_features\n",
    "        self.new_dim = new_dim\n",
    "        self.use_PCA = use_PCA\n",
    "        self.classifier = classifier\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    " \n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        # PCA \n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            self.sc = StandardScaler()\n",
    "            X_std = self.sc.fit_transform(X)\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X_pca = self.pca.fit_transform(X_std)\n",
    "            self.X_pca = X_pca\n",
    "        else:\n",
    "            self.X_pca = X\n",
    "\n",
    "        # generation of W, u\n",
    "     \n",
    "        d = self.X_pca.shape[1]\n",
    "        \n",
    "        self.W = np.sqrt(2*self.gamma)*np.random.normal(size=(self.n_features,d))\n",
    "        \n",
    "        self.u = 2*np.pi*np.random.rand(self.n_features)\n",
    "     \n",
    "        new_x = np.sqrt(2/self.n_features)*np.cos((self.X_pca.dot(self.W.T) + self.u))\n",
    "\n",
    "\n",
    "        self.sc_new = StandardScaler()\n",
    "        new_x = self.sc_new.fit_transform(new_x)\n",
    "\n",
    "        self.new_x = new_x\n",
    "\n",
    "\n",
    "        # Fitting logreg/SVM\n",
    "\n",
    "        if self.classifier == 'logreg':\n",
    "            clf = LogisticRegression(n_jobs=-1)\n",
    "            clf.fit(self.new_x, y)\n",
    "            self.clf = clf\n",
    "        \n",
    "        if self.classifier == 'SVM':\n",
    "            clf = SVC(kernel='linear')\n",
    "            clf.fit(self.new_x, y)\n",
    "            self.clf = clf\n",
    "        \n",
    "        return self.clf\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "      \n",
    "\n",
    "        new_x_test = np.sqrt(2/self.n_features)*np.cos((self.X_test_pca.dot(self.W.T) + self.u))\n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred_proba = self.clf.predict_proba(new_x_test)\n",
    "        \n",
    "        return pred_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "        new_x_test = np.sqrt(2/self.n_features)*np.cos((self.X_test_pca.dot(self.W.T) + self.u)) \n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred = self.clf.predict(new_x_test)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpnXHRxeZ_ju",
    "outputId": "2e6a9b12-8c5d-4fe3-d214-9e9e09edf274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 65.34981632232666 seconds (fit) ---\n",
      "--- 0.8155701160430908 seconds (predict) ---\n",
      "Accuracy LogReg: 0.8707\n"
     ]
    }
   ],
   "source": [
    "RFFPipe = RFFPipeline_5()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "RFFPipe.fit(x_train, y_train)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "preds = RFFPipe.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy LogReg: {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow! Accuracy = 0.8707 => качество больше, чем изначально при RFF (logreg) - 0.8671 на этом же датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZbzrbqybcK_"
   },
   "source": [
    "#### 2. Вариант с другим классификатором (SGD):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "lFGZGebdUUUk"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "class RFFPipeline_SGD(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='SGD'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        # 1-st step. PCA \n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            self.sc = StandardScaler()\n",
    "            X_std = self.sc.fit_transform(X)\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X_pca = self.pca.fit_transform(X_std)\n",
    "            self.X_pca = X_pca\n",
    "        else:\n",
    "            self.X_pca = X\n",
    "\n",
    "        # 2-nd step. sigma\n",
    "\n",
    "        var_hat_all = np.zeros(10**6)\n",
    "        for par in range(10**6):\n",
    "            i, j = np.random.randint(low=0, high=self.X_pca.shape[0], size=2)\n",
    "\n",
    "            while i-j == 0:\n",
    "              i, j = np.random.randint(low=0, high=self.X_pca.shape[0], size=2)\n",
    "  \n",
    "\n",
    "            res = np.sum((self.X_pca[i,:] - self.X_pca[j,:]) ** 2)\n",
    "            var_hat_all[par] = res\n",
    "            \n",
    "        est_med = np.median(var_hat_all)\n",
    "        self.est_med = est_med\n",
    "\n",
    "\n",
    "        # 3-d step. generating b, W\n",
    "        \n",
    "        b = np.random.uniform(-np.pi, np.pi, size=self.n_features)\n",
    "        \n",
    "        W = np.zeros((self.X_pca.shape[1], self.n_features))\n",
    "        W[:,:] = np.random.normal(loc=0, scale=np.sqrt(1/self.est_med), size=(self.X_pca.shape[1], self.n_features))\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "        # 4-th step. cos \n",
    "\n",
    "\n",
    "        new_x = np.cos(self.X_pca.dot(self.W) + self.b)\n",
    "\n",
    "\n",
    "        self.sc_new = StandardScaler()\n",
    "        new_x = self.sc_new.fit_transform(new_x)\n",
    "\n",
    "        self.new_x = new_x\n",
    "\n",
    "\n",
    "        # 5-th step. Fitting SGD\n",
    "\n",
    "\n",
    "        if self.classifier == 'SGD':\n",
    "            clf = SGDClassifier()\n",
    "            clf.fit(self.new_x, y)\n",
    "            self.clf = clf\n",
    "        \n",
    "        return self.clf\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "        \n",
    "        new_x_test = np.cos(self.X_test_pca.dot(self.W) + self.b)\n",
    "\n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred_proba = self.clf.predict_proba(new_x_test)\n",
    "        \n",
    "        return pred_proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        \n",
    "        if self.use_PCA==True:\n",
    "            X_test_std = self.sc.transform(X)\n",
    "            X_test_pca = self.pca.transform(X_test_std)\n",
    "            self.X_test_pca = X_test_pca\n",
    "        else:\n",
    "            self.X_test_pca = X\n",
    "\n",
    "        new_x_test = np.cos(self.X_test_pca.dot(self.W) + self.b)    \n",
    "\n",
    "        new_x_test = self.sc_new.transform(new_x_test)\n",
    "        pred = self.clf.predict(new_x_test)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRw1lLDfZxfZ",
    "outputId": "6c0f3b4f-c90c-4e53-86ae-ffebfbb02c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 297.9759159088135 seconds (fit) ---\n",
      "--- 0.6072912216186523 seconds (predict) ---\n",
      "Accuracy LogReg: 0.8511\n"
     ]
    }
   ],
   "source": [
    "RFFPipe = RFFPipeline_SGD()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "RFFPipe.fit(x_train, y_train)\n",
    "print(\"--- %s seconds (fit) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "preds = RFFPipe.predict(x_test)\n",
    "print(\"--- %s seconds (predict) ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "print('Accuracy SGD: {}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество ниже, чем в RFF (logreg), но выше, чем в RFF (SVM)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"homework-practice-08-random-features.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
